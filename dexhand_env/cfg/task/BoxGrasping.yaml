# @package task
name: BoxGrasping
physics_engine: physx

# Simulation parameters
sim:
  dt: 0.005                       # High-fidelity physics (200 Hz) for optimal performance
  substeps: 4                     # Reduced due to higher frequency
  gravity: [0.0, 0.0, -9.81]
  num_client_threads: 0

  physx:
    solver_type: 1                # 0: PCG, 1: TGS
    num_position_iterations: 16   # Optimized for smaller timestep
    num_velocity_iterations: 0    # Set to 0 based on NVIDIA recommendations
    contact_offset: 0.001         # Balanced value for 200 Hz physics
    rest_offset: 0.003            # Appropriate for smaller timestep
    bounce_threshold_velocity: 0.15  # Moderate value for 200 Hz
    max_depenetration_velocity: 0.2  # Optimized for stable contact
    default_buffer_size_multiplier: 4.0  # Optimized for performance
    num_subscenes: 0
    contact_collection: 1         # 1: CC_LAST_SUBSTEP (critical for GPU pipeline)
    gpu_contact_pairs_per_env: 512  # Contact pairs per environment (will be auto-multiplied by num_envs)
    always_use_articulations: true  # Always use articulations for stability
    num_threads: 4                # Standard CPU threads

env:
  numEnvs: ${resolve_default:2048,${..num_envs}}
  envSpacing: 2.0
  episodeLength: 2000  # 10 seconds at 200Hz

  # Action space configuration
  controlMode: position_delta
  policyControlsHandBase: true
  policyControlsFingers: true

  # Default targets for uncontrolled DOFs (not used in this task since policy controls all)
  defaultBaseTargets: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  defaultFingerTargets: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

  # Component-wise velocity limits for position_delta mode action scaling
  maxFingerJointVelocity: 1.0     # Maximum velocity for each finger joint (rad/s)
  maxBaseLinearVelocity: 0.5      # Maximum velocity for each base linear axis (m/s)
  maxBaseAngularVelocity: 1.5     # Maximum velocity for each base angular axis (rad/s)

  # Initial pose
  initialHandPos: [0.0, 0.0, 0.5]
  initialHandRot: [0.0, 0.0, 0.0, 1.0]

  # Logging configuration
  logLevel: "INFO"
  enableComponentDebugLogs: false

  # Policy observation keys - what the policy actually sees (blind policy design)
  policyObservationKeys:
    - base_dof_pos
    - active_finger_dof_pos
    - base_dof_vel
    - active_finger_dof_vel
    - contact_binary      # Primary sensing
    - contact_duration    # Temporal sensing
    - hand_pose          # Correct key name (not hand_base_pose)
    - prev_actions
    - fingertip_poses_world
    # NO box observations - policy is blind!
    # All other observations (box pose, distances) are computed for rewards/analysis only

  # Binary contact threshold (1N)
  contactBinaryThreshold: 1.0

  # Contact force bodies (for contact sensing)
  contactForceBodies:
    - "r_f_link1_4"  # thumb distal phalanx
    - "r_f_link2_4"  # index distal phalanx
    - "r_f_link3_4"  # middle distal phalanx
    - "r_f_link4_4"  # ring distal phalanx
    - "r_f_link5_4"  # pinky distal phalanx

  # Contact force visualization settings
  contactVisualization:
    enabled: true
    forceThreshold: 0.1
    forceMaxIntensity: 100.0
    baseColor: [1.0, 0.2, 0.2]
    defaultColor: [0.7, 0.7, 0.7]

  # Box properties
  box:
    size: 0.05  # 5cm cube
    mass: 0.1   # 100g
    friction: 1.0
    restitution: 0.0
    initial_position:
      xy_range: 0.02    # Â±2cm randomization
      z: 0.025          # Fixed on table (box half-size)

  # Termination criteria
  termination:
    # Specify which criteria are active (fail-fast if any are missing)
    activeSuccessCriteria: ["grasp_lift_success"]
    activeFailureCriteria: ["hitting_ground"]

    # Height thresholds for ground collision detection
    height_safety:
      handbase_threshold: 0.0
      fingertip_threshold: 0.0
      fingerpad_threshold: 0.0

  # Reward weights configuration
  rewardWeights:
    # Common rewards (small weights to prevent dominating task rewards)
    alive: 0.01                      # Small alive bonus
    height_safety: 0.1               # Height safety penalty
    finger_velocity: 0.01            # Velocity penalties
    hand_velocity: 0.01
    hand_angular_velocity: 0.01
    joint_limit: 0.05                # Joint limit penalty
    finger_acceleration: 0.005
    hand_acceleration: 0.005
    hand_angular_acceleration: 0.005
    contact_stability: 0.02

    # Task-specific rewards (main learning signal)
    object_height: 2.0              # Main reward for lifting object
    grasp_approach: 1.0              # Reward any contact with object
    finger_to_object: 1.0           # Reward for getting fingers close
    hand_to_object: 1.0              # Reward for getting hand close

    # Termination rewards (one-time at episode end)
    termination_success: 2000.0       # Large bonus for successful grasp and lift
    termination_failure_penalty: 1000.0       # Penalty for failure (touching ground, etc.)
    termination_timeout_penalty: 100.0       # Small penalty for not completing task

  # Task-specific parameters
  task_params:
    success_height_threshold: 0.2     # Object must be lifted above this height (meters)
    contact_duration_threshold: 2.0   # Minimum contact duration for success (seconds)
    min_fingers_for_grasp: 2          # Minimum number of fingers required for valid grasp
    max_box_distance: 0.5             # Reset if box moves beyond this distance (meters)

# Task configuration
task:
  randomize: true  # Enable position randomization
